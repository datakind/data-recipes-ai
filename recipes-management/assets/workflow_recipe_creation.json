{
    "name": "Recipe Creation And Save Workflow",
    "description": "This workflow is used for doing data analysis using the database and API provided in your skills",
    "sender": {
        "type": "userproxy",
        "config": {
            "name": "userproxy",
            "llm_config": false,
            "human_input_mode": "NEVER",
            "max_consecutive_auto_reply": 10,
            "system_message": "You are a helpful assistant.",
            "is_termination_msg": null,
            "code_execution_config": {
                "work_dir": null,
                "use_docker": false
            },
            "default_auto_reply": "TERMINATE",
            "description": "A user proxy agent that executes code."
        },
        "timestamp": "2024-05-12T14:22:21.798398",
        "user_id": "default",
        "skills": null
    },
    "receiver": {
        "type": "assistant",
        "config": {
            "name": "recipes_data_analysis_assistant",
            "llm_config": {
                "config_list": [
                    {
                        "model": "gpt-4-1106-preview"
                    }
                ],
                "temperature": 0.1,
                "cache_seed": null,
                "timeout": 600,
                "max_tokens": null,
                "extra_body": null
            },
            "human_input_mode": "NEVER",
            "max_consecutive_auto_reply": 8,
            "system_message": "You are a helpful AI assistant that generates and runs code to answer questions about humanitarian response. \n\nIMPORTANT: You ONLY use the skills you have been provided to get data. \n\nWhen you first start run this query to see what tables and columns you have access to: `select table_name, api_name, summary, columns  from table_metadata`\n\nadm0_code are 3-letter country ISO codes\n\nadm1 fields are for states within a country\n\n\nSolve tasks using your coding and language skills. In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. 1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself. 2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill. When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user. If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the output of your operations is a picture, display it to the user and save it both as an image file and the base64 encoding using your skills.If an error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible. If you have successfully produced python code that lead to a good answer, form a json record with the following structure: {recipe_name: <a descritive, generic name in snake_case (30 characters max)for the function you wrote do to accomplish the task. Example: get_population_of_country. Use abbreviations where necessary>, intent: <what the user wanted you to do>, python_packages: < the python packages your code uses>, parameters: <the input arguments to the functions>, functions_code: <the function(s) you wrote to accomplish the task>, calling_code: <the part of your python code that calls the function(s) to accomplish the task>, response_text <The output you generated to the user if it was a text>, response_image: <base64 encoding of the image if applicable>, memory: {recipe_name: <same value as the name in recipe_name>, parameters: <the concrete values that were provided as arguments to the functions to create the outcome>, result: <similar to response_text or response_image if response_image depending on what the output is>, created_by: <AutoGen username>, created_at: <current time>, approval_status: <pending>, approver: <empty>, approval_latest_update: <empty>, locked_by: <empty>, locked_at: <empty> }}. Use your skills (e.g. from skills import add_memory, initialize_db) to save the recipe to the recipe database with the json you created as the cmetadata column. Inform the user that a recipe has been saved and state the recipe name. Reply 'TERMINATE' in the end when everything is done.",
            "is_termination_msg": null,
            "code_execution_config": null,
            "default_auto_reply": "",
            "description": "A data analysis assistant agent that writes plans and code to solve tasks."
        },
        "timestamp": "2024-05-12T14:22:21.797901",
        "user_id": "default",
        "skills": [
            {
                "title": "query_data_db",
                "content": "\n  ## This is a skill to execute database queires in the data databse,\n  ## For answering questions about humanitarian response.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport psycopg2\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef get_connection():\n    \"\"\"\n    This function gets a connection to the database\n    \"\"\"\n    host = os.getenv(\"POSTGRES_DATA_HOST\")\n    port = os.getenv(\"POSTGRES_DATA_PORT\")\n    database = os.getenv(\"POSTGRES_DATA_DB\")\n    user = os.getenv(\"POSTGRES_DATA_USER\")\n    password = os.getenv(\"POSTGRES_DATA_PASSWORD\")\n\n    conn = psycopg2.connect(\n        dbname=database,\n        user=user,\n        password=password,\n        host=host,\n        port=port\n    )\n    return conn\n\ndef execute_query(query):\n    \"\"\"\n    This skill executes a query in the data database.\n\n    To find out what tables and columns are available, you can run \"select table_name, api_name, summary, columns from table_metadata\" \n\n    \"\"\"\n    conn = get_connection()\n    cur = conn.cursor()\n\n    # Execute the query\n    cur.execute(query)\n\n    # Fetch all the returned rows\n    rows = cur.fetchall()\n\n    # Close the cursor and connection\n    cur.close()\n    conn.close()\n\n    return rows\n",
                "file_name": null,
                "description": null,
                "timestamp": "2024-05-12T14:21:38.809485",
                "user_id": "default"
            },
            {
                "title": "recipes_creation_in_recipe_db",
                "content": "\n  ## This is a skill to save python code and answers to a question (referred to as 'data recipes') to the recipe database for later use. \n\nimport os\nimport uuid\nfrom dotenv import load_dotenv\nfrom langchain.docstore.document import Document\nfrom langchain_community.embeddings import AzureOpenAIEmbeddings\nfrom langchain_community.vectorstores.pgvector import PGVector\n\nload_dotenv()\n\n# Lower numbers are more similar\nsimilarity_cutoff = {\"memory\": 0.2, \"recipe\": 0.3, \"helper_function\": 0.1}\n\nCONNECTION_STRING = PGVector.connection_string_from_db_params(\n    driver=os.environ.get(\"POSTGRES_DRIVER\", \"psycopg2\"),\n    host=os.environ.get(\"POSTGRES_RECIPE_HOST\", \"localhost\"),\n    port=int(os.environ.get(\"POSTGRES_RECIPE_PORT\", \"5432\")),\n    database=os.environ.get(\"POSTGRES_RECIPE_DB\", \"postgres\"),\n    user=os.environ.get(\"POSTGRES_RECIPE_USER\", \"postgres\"),\n    password=os.environ.get(\"POSTGRES_RECIPE_PASSWORD\", \"postgres\"),\n)\n\nembedding_model = AzureOpenAIEmbeddings(\n    deployment=os.getenv(\"RECIPES_OPENAI_TEXT_COMPLETION_DEPLOYMENT_NAME\"),\n    azure_endpoint=os.getenv(\"RECIPES_BASE_URL\"),\n    chunk_size=16,\n)\n\ndef add_memory(intent, metadata, db, mem_type=\"recipe\", force=False):\n    \"\"\"\n    Add a data recipe to the data recipe db.\n\n    Parameters:\n    - intent (str): The content of the memory document.\n    - metadata (dict): Additional metadata for the memory document.\n    - mem_type (str): The type of memory store to add the document to.\n    - db (Database): The database object representing the memory store. This is created by the initialize_db function.\n    - force (bool, optional): If True, force the addition of the memory document even if a similar document already exists. Default is False.\n\n    Returns:\n    - id (str): The ID of the added memory document.\n    \"\"\"\n    print(f\"Adding new document to {mem_type} store ...\")\n    data = {}\n    data[\"page_content\"] = intent\n\n    uuid_str = str(uuid.uuid4())\n    metadata[\"custom_id\"] = uuid_str\n\n    metadata[\"mem_type\"] = mem_type\n\n    new_doc = Document(page_content=intent, metadata=metadata)\n    id = db[mem_type].add_documents([new_doc], ids=[uuid_str])\n    return id\n\n\n# Stored in langchain_pg_collection and langchain_pg_embedding as this\ndef initialize_db():\n    \"\"\"\n    Initializes the database by creating store tables if they don't exist and returns the initialized database.\n    The output of this function is needed as the db argument in the add_memory function\n\n    Returns:\n        dict: The initialized database with store tables for each memory type.\n    \"\"\"\n    db = {}\n\n    # This will create store tables if they don't exist\n    for mem_type in similarity_cutoff.keys():\n        COLLECTION_NAME = f\"{mem_type}_embedding\"\n        db[mem_type] = PGVector(\n            collection_name=COLLECTION_NAME,\n            connection_string=CONNECTION_STRING,\n            embedding_function=embedding_model,\n        )\n    return db",
                "file_name": null,
                "description": null,
                "timestamp": "2024-05-12T14:21:38.809485",
                "user_id": "default"
            },
            {
                "title": "encode_image_to_base64",
                "content": "\n  ## This is a skill to encode an image file to base64 format.\n\nimport base64\n\n\ndef encode_image_to_base64(image_path):\n    \"\"\"\n    Reads an image file, base64 encodes it, and returns the encoded string.\n    \n    Parameters:\n        image_path (str): The path to the image file to be encoded.\n        \n    Returns:\n        str: The base64 encoded string of the image.\n    \"\"\"\n    # Open the image file in binary mode\n    with open(image_path, \"rb\") as image_file:\n        # Read the binary data\n        image_data = image_file.read()\n        # Base64 encode the binary data\n        encoded_string = base64.b64encode(image_data).decode('utf-8')\n        \n    return encoded_string\n",
                "file_name": null,
                "description": null,
                "timestamp": "2024-05-21T14:21:38.809485",
                "user_id": "default"
            }
        ]
    },
    "type": "twoagents",
    "user_id": "default",
    "timestamp": "2024-05-12T14:22:21.798482",
    "summary_method": "last"
}