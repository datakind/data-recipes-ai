{
    "name": "Recipe Creation And Save Workflow",
    "description": "This workflow is used for doing data analysis using the database and API provided in your skills",
    "sender": {
        "type": "userproxy",
        "config": {
            "name": "userproxy",
            "llm_config": false,
            "human_input_mode": "NEVER",
            "max_consecutive_auto_reply": 10,
            "system_message": "You are a helpful assistant.",
            "is_termination_msg": null,
            "code_execution_config": {
                "work_dir": null,
                "use_docker": false
            },
            "default_auto_reply": "TERMINATE",
            "description": "A user proxy agent that executes code."
        },
        "timestamp": "2024-05-12T14:22:21.798398",
        "user_id": "default",
        "skills": null
    },
    "receiver": {
        "type": "assistant",
        "config": {
            "name": "recipes_data_analysis_assistant",
            "llm_config": {
                "config_list": [
                    {
                        "model": "gpt-4-1106-preview"
                    }
                ],
                "temperature": 0.1,
                "cache_seed": null,
                "timeout": 600,
                "max_tokens": null,
                "extra_body": null
            },
            "human_input_mode": "NEVER",
            "max_consecutive_auto_reply": 8,
            "system_message": "You are a helpful AI assistant that generates and runs code to answer questions about humanitarian response. \n\nIMPORTANT: You ONLY use the skills you have been provided to get data. \n\nWhen you first start run this query to see what tables and columns you have access to: `select table_name, api_name, summary, columns  from table_metadata`\n\nadm0_code are 3-letter country ISO codes\n\nadm1 fields are for states within a country\n\n\nSolve tasks using your coding and language skills. In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. 1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself. 2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill. When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user. If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the output of your operations is a picture, display it to the user and save it both as an image file and the base64 encoding using your skills.If an error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible. If you have successfully produced python code that lead to a an answer to the user, ask the user if they want to save the code and the output as a 'data recipe'. If they do, form a json record with the following structure: {recipe_name: <a descritive, generic name in snake_case (30 characters max)for the function you wrote do to accomplish the task. Example: get_population_of_country. Use abbreviations where necessary>, intent: <what the user wanted you to do>, python_packages: < the python packages your code uses>, parameters: <the input arguments to the functions>, functions_code: <the function(s) you wrote to accomplish the task>, calling_code: <the part of your python code that calls the function(s) to accomplish the task>, response_text <The output you generated to the user if it was a text>, response_image: <base64 encoding of the image if applicable>, memory: {recipe_name: <same value as the name in recipe_name>, parameters: <the concrete values that were provided as arguments to the functions to create the outcome>, result: <similar to response_text or response_image if response_image depending on what the output is>, created_by: <AutoGen username>, created_at: <current time>, approval_status: <pending>, approver: <empty>, approval_latest_update: <empty>, locked_by: <empty>, locked_at: <empty> }}. Use your skills (e.g. from skills import add_memory, initialize_db) to save the recipe to the database with the json you created as the cmetadata column. Reply 'TERMINATE' in the end when everything is done.",
            "is_termination_msg": null,
            "code_execution_config": null,
            "default_auto_reply": "",
            "description": "A data analysis assistant agent that writes plans and code to solve tasks."
        },
        "timestamp": "2024-05-12T14:22:21.797901",
        "user_id": "default",
        "skills": [
            {
                "title": "generate_images",
                "content": "from typing import List\nimport uuid\nimport requests  # to perform HTTP requests\nfrom pathlib import Path\n\nfrom openai import OpenAI\n\n\ndef generate_and_save_images(query: str, image_size: str = \"1024x1024\") -> List[str]:\n    \"\"\"\n    Function to paint, draw or illustrate images based on the users query or request. Generates images from a given query using OpenAI's DALL-E model and saves them to disk.  Use the code below anytime there is a request to create an image.\n\n    :param query: A natural language description of the image to be generated.\n    :param image_size: The size of the image to be generated. (default is \"1024x1024\")\n    :return: A list of filenames for the saved images.\n    \"\"\"\n\n    client = OpenAI()  # Initialize the OpenAI client\n    response = client.images.generate(model=\"dall-e-3\", prompt=query, n=1, size=image_size)  # Generate images\n\n    # List to store the file names of saved images\n    saved_files = []\n\n    # Check if the response is successful\n    if response.data:\n        for image_data in response.data:\n            # Generate a random UUID as the file name\n            file_name = str(uuid.uuid4()) + \".png\"  # Assuming the image is a PNG\n            file_path = Path(file_name)\n\n            img_url = image_data.url\n            img_response = requests.get(img_url)\n            if img_response.status_code == 200:\n                # Write the binary content to a file\n                with open(file_path, \"wb\") as img_file:\n                    img_file.write(img_response.content)\n                    print(f\"Image saved to {file_path}\")\n                    saved_files.append(str(file_path))\n            else:\n                print(f\"Failed to download the image from {img_url}\")\n    else:\n        print(\"No image data found in the response!\")\n\n    # Return the list of saved files\n    return saved_files\n\n\n# Example usage of the function:\n# generate_and_save_images(\"A cute baby sea otter\")\n",
                "file_name": null,
                "description": "This skill generates images from a given query using OpenAI's DALL-E model and saves them to disk.",
                "timestamp": "2024-05-12T14:22:21.797899",
                "user_id": "default"
            },
            {
                "title": "query_data_db",
                "content": "\n  ## This is a skill to execute database queires in the data databse,\n  ## For answering questions about humanitarian response.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport psycopg2\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef get_connection():\n    \"\"\"\n    This function gets a connection to the database\n    \"\"\"\n    host = os.getenv(\"POSTGRES_DATA_HOST\")\n    port = os.getenv(\"POSTGRES_DATA_PORT\")\n    database = os.getenv(\"POSTGRES_DATA_DB\")\n    user = os.getenv(\"POSTGRES_DATA_USER\")\n    password = os.getenv(\"POSTGRES_DATA_PASSWORD\")\n\n    conn = psycopg2.connect(\n        dbname=database,\n        user=user,\n        password=password,\n        host=host,\n        port=port\n    )\n    return conn\n\ndef execute_query(query):\n    \"\"\"\n    This skill executes a query in the data database.\n\n    To find out what tables and columns are available, you can run \"select table_name, api_name, summary, columns from table_metadata\" \n\n    \"\"\"\n    conn = get_connection()\n    cur = conn.cursor()\n\n    # Execute the query\n    cur.execute(query)\n\n    # Fetch all the returned rows\n    rows = cur.fetchall()\n\n    # Close the cursor and connection\n    cur.close()\n    conn.close()\n\n    return rows\n",
                "file_name": null,
                "description": null,
                "timestamp": "2024-05-12T14:21:38.809485",
                "user_id": "default"
            },
            {
                "title": "save_recipe_to_db",
                "content": "\n## This is a skill (consisting of multiple functions) to save python code (referred to as 'data recipes') and answers (referred to as 'memories') to a question  to the recipe postgres database with the vector extension for later use.\n\nimport os\nimport psycopg2\nfrom langchain.docstore.document import Document\nfrom langchain_community.vectorstores.pgvector import PGVector\nfrom langchain_community.embeddings import AzureOpenAIEmbeddings\nfrom langchain.chat_models import AzureChatOpenAI\nimport uuid\nimport json\n\n# Lower numbers are more similar\nsimilarity_cutoff = {\n    \"memory\": 0.2,\n    \"recipe\": 0.3,\n    \"helper_function\": 0.1\n}\n\nCONNECTION_STRING = PGVector.connection_string_from_db_params(\n    driver=os.environ.get(\"POSTGRES_DRIVER\", \"psycopg2\"),\n    host=os.environ.get(\"POSTGRES_RECIPE_HOST\", \"localhost\"),\n    port=int(os.environ.get(\"POSTGRES_RECIPE_PORT\", \"5432\")),\n    database=os.environ.get(\"POSTGRES_RECIPE_DB\", \"postgres\"),\n    user=os.environ.get(\"POSTGRES_RECIPE_USER\", \"postgres\"),\n    password=os.environ.get(\"POSTGRES_RECIPE_PASSWORD\", \"postgres\")\n)\n\nembedding_model = AzureOpenAIEmbeddings(deployment=os.getenv(\"RECIPES_OPENAI_TEXT_COMPLETION_DEPLOYMENT_NAME\"), \n                                        azure_endpoint=os.getenv(\"RECIPES_BASE_URL\"), \n                                        chunk_size=16)\n\nchat = AzureChatOpenAI(model_name=\"gpt-35-turbo\", \n                       azure_endpoint=os.getenv(\"RECIPES_BASE_URL\"),api_version= os.getenv(\"RECIPES_OPENAI_API_VERSION\"), temperature=1, max_tokens=1000)\n\n\ndef add_memory(intent, metadata, db, mem_type='recipe', force=False):\n    \"\"\"\n    Add a data recipe to the data recipe db.\n\n    Parameters:\n    - intent (str): The content of the memory document.\n    - metadata (dict): Additional metadata for the memory document.\n    - mem_type (str): The type of memory store to add the document to.\n    - db (Database): The database object representing the memory store. This is created by the initialize_db function.\n    - force (bool, optional): If True, force the addition of the memory document even if a similar document already exists. Default is False.\n\n    Returns:\n    - id (str): The ID of the added memory document.\n    \"\"\"\n    print(f\"Adding new document to {mem_type} store ...\")\n    data = {}\n    data['page_content'] = intent\n\n    uuid_str = str(uuid.uuid4())\n    metadata['custom_id'] = uuid_str\n\n    metadata['mem_type'] = mem_type\n\n    new_doc =  Document(\n        page_content=intent,\n        metadata=metadata\n    )\n    id = db[mem_type].add_documents(\n        [new_doc],\n        ids=[uuid_str]\n    )\n    return id\n\n# Stored in langchain_pg_collection and langchain_pg_embedding as this\ndef initialize_db():\n    \"\"\"\n    Initializes the database by creating store tables if they don't exist and returns the initialized database.\n    The output of this function is needed as the db argument in the add_memory function\n\n    Returns:\n        dict: The initialized database with store tables for each memory type.\n    \"\"\"\n    db = {}\n\n    # This will create store tables if they don't exist\n    for mem_type in similarity_cutoff.keys():\n        COLLECTION_NAME = f\"{mem_type}_embedding\"\n        db[mem_type] = PGVector(\n            collection_name=COLLECTION_NAME,\n            connection_string=CONNECTION_STRING,\n            embedding_function=embedding_model,\n        )\n    return db",
                "file_name": null,
                "description": null,
                "timestamp": "2024-05-21T14:21:38.809485",
                "user_id": "default"
            },
            {
                "title": "encode_image_to_base64",
                "content": "\n  ## This is a skill to encode an image file to base64 format.\n\nimport base64\n\n\ndef encode_image_to_base64(image_path):\n    \"\"\"\n    Reads an image file, base64 encodes it, and returns the encoded string.\n    \n    Parameters:\n        image_path (str): The path to the image file to be encoded.\n        \n    Returns:\n        str: The base64 encoded string of the image.\n    \"\"\"\n    # Open the image file in binary mode\n    with open(image_path, \"rb\") as image_file:\n        # Read the binary data\n        image_data = image_file.read()\n        # Base64 encode the binary data\n        encoded_string = base64.b64encode(image_data).decode('utf-8')\n        \n    return encoded_string\n",
                "file_name": null,
                "description": null,
                "timestamp": "2024-05-21T14:21:38.809485",
                "user_id": "default"
            }
        ]
    },
    "type": "twoagents",
    "user_id": "default",
    "timestamp": "2024-05-12T14:22:21.798482",
    "summary_method": "last"
}