import asyncio
import datetime
import glob
import json
import os
import sys
import zipfile

import pandas as pd
import requests
from dotenv import load_dotenv
from jinja2 import Environment, FileSystemLoader
from openai import AzureOpenAI, OpenAI

load_dotenv("../../.env")

api_key = os.environ.get("ASSISTANTS_API_KEY")
assistant_id = os.environ.get("ASSISTANTS_ID")
model = os.environ.get("ASSISTANTS_MODEL")
api_type = os.environ.get("ASSISTANTS_API_TYPE")
api_endpoint = os.environ.get("ASSISTANTS_BASE_URL")
api_version = os.environ.get("ASSISTANTS_API_VERSION")
bot_name = os.environ.get("ASSISTANTS_BOT_NAME")
environment = Environment(loader=FileSystemLoader("templates/"))

file_to_func_map_loc = "./file_to_func_map.json"
data_files_location = "../../ingestion/api"

# Needed to get common fields standard_names
INTEGRATION_CONFIG = "../../ingestion/ingestion.config"
SYSTEM_PROMPT = "instructions.txt"

if api_type == "openai":
    print("Using OpenAI API")
    client = OpenAI(api_key=api_key)
elif api_type == "azure":
    print("Using Azure API")
    print(f"Endpoint: {api_endpoint}")
    client = AzureOpenAI(
        api_key=api_key,
        api_version=api_version,
        azure_endpoint=api_endpoint,
        default_headers={"OpenAI-Beta": "assistants=v2"},
    )
else:
    print("API type not supported")
    sys.exit(1)


def get_common_field_standard_names():
    """
    Get the standard names of common fields from the integration configuration file.

    Returns:
        list: A list of standard names of common fields.
    """
    with open(INTEGRATION_CONFIG) as f:
        print(f"Reading {INTEGRATION_CONFIG}")
        config = json.load(f)
    return config["standard_names"]


def get_manually_defined_functions():
    """
    Get a list of manually defined functions.

    Returns:
        list: A list of dictionaries representing the manually defined functions.
    """
    # functions = [
    #     {
    #         "function": {
    #             "name": "get_info_about_datasets",
    #             "parameters": {},
    #             "description": """
    #                 Get a JSON object containing information about the datasets you have access to.
    #                 This includes which types of data, the countries they include and columns within each datafiles.
    #                 Use this function for questions about the data you have
    #             """,
    #         }
    #     }
    # ]
    functions = []
    if len(functions) > 0:
        functions_openai_fmt = []
        for f in functions:
            f = {
                "type": "function",
                "function": f["function"],
            }
            functions_openai_fmt.append(f)
    return functions_openai_fmt


def upload_files_to_openai(standard_names):
    """
    Uploads files to OpenAI and returns a prompt string and a list of file IDs.

    Args:
        standard_names (dict): A dictionary containing common field standard_names.

    Returns:
        file_prompt (str): A string containing information about the uploaded files.
        file_ids (list): A list of file IDs generated by OpenAI.
    """

    files = []
    files += glob.glob(f"{data_files_location}/**/*.csv", recursive=True)
    files += glob.glob(f"{data_files_location}/**/*geoBoundaries*.zip", recursive=True)
    file_prompt = ""
    file_ids = []

    # sort files with csv first, then zip
    files = sorted(files, key=lambda x: x.split(".")[-1])

    datafiles = []
    for f in files:
        print(f)
        countries = ""
        first_line = ""
        # Get column standard_names from first line
        if f.endswith(".csv"):
            df = pd.read_csv(f)
            first_line = list(df.columns)
            if standard_names["country_code_field"] in first_line:
                countries = list(df[standard_names["country_code_field"]].unique())

        print(f"Uploading {f} ...")
        file = client.files.create(file=open(f, "rb"), purpose="assistants")

        r = {}
        if f.endswith(".csv"):
            file_loc = f"/mnt/data/{file.id}"
            r["file_location"] = file_loc
            r["_original_file_name"] = f.split("/")[-1]
            metadata_file = f.replace(".csv", "_meta.json")
            r["description"] = "This is CSV data"

            # If we have a metadata file, use that
            if os.path.exists(metadata_file):
                with open(metadata_file) as mf:
                    metadata = json.load(mf)
                    description = ""
                    for f in ["tags", "summary", "description"]:
                        if f in metadata["get"]:
                            description += str(metadata["get"][f]) + "\n"
                    r["description"] = description

            r["columns"] = first_line
            r["countries"] = countries
        elif "geoBoundaries" in f:
            r["zip_file_location_with_shapefiles"] = f"/mnt/data/{file.id}"
            r["_original_file_name"] = f
            r["description"] = (
                "This file contains administrative boundary data for countries and admin level as specified"
            )
            r["admin_level"] = f.split("geoBoundaries-")[1][0:4]
            # Intentionall removed some columns here for clarity
            r["columns"] = [
                "Shape_Leng",
                "Shape_Area",
                f"{standard_names['admin0_code_field']}",
                f"{standard_names['admin1_code_field']}",
                f"{standard_names['admin2_code_field']}",
                f"{standard_names['admin3_code_field']}",
                "ADM1_REF",
                "date",
                "validOn",
                "validTo",
                "geometry",
            ]

            with zipfile.ZipFile(f, "r") as zip_ref:
                shape_files = []
                files_in_zip = zip_ref.namelist()
                for zf in files_in_zip:
                    if zf.endswith(".shp"):
                        r2 = {}
                        r2["shape_file"] = zf
                        r2["country"] = zf[0:3].upper()
                        shape_files.append(r2)

            r["shapefiles"] = shape_files

        datafiles.append(r)
        print(json.dumps(datafiles, indent=4))

        file_ids.append(file.id)

    file_prompt = json.dumps(datafiles, indent=4)

    return file_prompt, file_ids


def create_update_assistant():
    """
    Creates or updates a humanitarian response assistant.

    To force creation of a new assistant, be sure that ASSITANT_ID is not set in the .env file.

    """

    standard_names = get_common_field_standard_names()
    files_prompt, file_ids = upload_files_to_openai(standard_names)

    # Load code examples
    template = environment.get_template("sample_code.jinja")
    sample_code = template.render(admin1_code_name=standard_names["country_code_field"])

    # Populate system prompt
    template = environment.get_template("assistant_instructions.jinja")
    instructions = template.render(
        admin0_code_field=standard_names["admin0_code_field"],
        admin1_code_field=standard_names["admin1_code_field"],
        admin2_code_field=standard_names["admin2_code_field"],
        admin3_code_field=standard_names["admin3_code_field"],
        sample_code=sample_code,
        files_prompt=files_prompt,
    )

    # Save for debugging
    with open(SYSTEM_PROMPT, "w") as f:
        f.write(instructions)

    tools = [{"type": "code_interpreter"}]

    # Find if agent exists. v1 needs a try/except for this, TODO upgrade to v2 API
    try:
        print(
            f"Updating existing assistant {assistant_id} {bot_name} and model {model} ..."
        )
        assistant = client.beta.assistants.update(
            assistant_id,
            name=bot_name,
            instructions=instructions,
            tools=tools,
            model=model,
            file_ids=file_ids,
        )
    except Exception:
        print(f"Creating assistant with model {model} ...")
        assistant = client.beta.assistants.create(
            name=bot_name,
            instructions=instructions,
            tools=tools,
            model=model,
            file_ids=file_ids,
        )
        print("Assistant created!! Here is the assistant ID:")
        print(assistant.id)
        print("Now save the ID in your .env file so next time it's updated")


if __name__ == "__main__":
    create_update_assistant()
